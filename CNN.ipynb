{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6e40f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5334e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "521fe502",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 4\n",
    "batch_size = 4\n",
    "lr = .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4546af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5,.5,.5),(.5,.5,.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff7f3963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c7aebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['plane','car','bird','cat','deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25a75745",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(-1,16*5*5)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a9ed2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1f23c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8633a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/4, Step 2000/12500, loss: 2.2717\n",
      "epoch 1/4, Step 4000/12500, loss: 2.3034\n",
      "epoch 1/4, Step 6000/12500, loss: 2.2922\n",
      "epoch 1/4, Step 8000/12500, loss: 2.3092\n",
      "epoch 1/4, Step 10000/12500, loss: 2.2828\n",
      "epoch 1/4, Step 12000/12500, loss: 2.2526\n",
      "epoch 2/4, Step 2000/12500, loss: 1.8292\n",
      "epoch 2/4, Step 4000/12500, loss: 2.4604\n",
      "epoch 2/4, Step 6000/12500, loss: 1.4113\n",
      "epoch 2/4, Step 8000/12500, loss: 1.5540\n",
      "epoch 2/4, Step 10000/12500, loss: 1.9350\n",
      "epoch 2/4, Step 12000/12500, loss: 1.7392\n",
      "epoch 3/4, Step 2000/12500, loss: 1.3211\n",
      "epoch 3/4, Step 4000/12500, loss: 1.2573\n",
      "epoch 3/4, Step 6000/12500, loss: 2.1173\n",
      "epoch 3/4, Step 8000/12500, loss: 1.8610\n",
      "epoch 3/4, Step 10000/12500, loss: 1.7893\n",
      "epoch 3/4, Step 12000/12500, loss: 1.9246\n",
      "epoch 4/4, Step 2000/12500, loss: 1.3137\n",
      "epoch 4/4, Step 4000/12500, loss: 1.2576\n",
      "epoch 4/4, Step 6000/12500, loss: 1.8738\n",
      "epoch 4/4, Step 8000/12500, loss: 1.4046\n",
      "epoch 4/4, Step 10000/12500, loss: 1.3221\n",
      "epoch 4/4, Step 12000/12500, loss: 0.9695\n",
      "finish Training\n"
     ]
    }
   ],
   "source": [
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if (i+1)%2000 == 0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, Step {i+1}/{n_total_steps}, loss: {loss.item():.4f}')\n",
    "print('finish Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8a330e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:28: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
      "<>:28: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
      "<ipython-input-18-c70b502d70b6>:28: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
      "  acc_class = 100*0(n_class_correct[i]/n_class_samples[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy46.654\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-c70b502d70b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m           \u001b[0macc_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_class_correct\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn_class_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m           \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Class Accuracy {acc_class}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    \n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted==labels).sum().item()\n",
    "        \n",
    "        for i in range(0,batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            \n",
    "            if(label==pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "            \n",
    "    acc = 100.0*(n_correct/n_samples)\n",
    "    print('Total Accuracy'+str(acc))\n",
    "    \n",
    "    for i in range(10):\n",
    "          acc_class = 100*0(n_class_correct[i]/n_class_samples[i])\n",
    "          print(f'Class Accuracy {acc_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29efe4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
